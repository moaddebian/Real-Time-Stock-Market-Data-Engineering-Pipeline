# Real-Time Stock Market Data Engineering Pipeline

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache-Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

</div>

---

## Overview

Ce projet est une **solution complÃ¨te d'ingÃ©nierie de donnÃ©es en temps rÃ©el** qui simule et traite des donnÃ©es boursiÃ¨res en utilisant Apache Kafka comme systÃ¨me de messagerie distribuÃ©. Il intÃ¨gre des fonctionnalitÃ©s avancÃ©es d'analytics, de visualisation interactive, et une API REST complÃ¨te pour l'analyse et l'interrogation des donnÃ©es.

Le pipeline permet de :
- IngÃ©rer des donnÃ©es boursiÃ¨res en temps rÃ©el via Kafka
- Calculer automatiquement des indicateurs techniques (SMA, EMA, RSI, VolatilitÃ©)
- DÃ©tecter des anomalies et alertes en temps rÃ©el
- Stocker les donnÃ©es de maniÃ¨re optimisÃ©e (format Parquet avec 90% de compression)
- Visualiser les donnÃ©es via un dashboard interactif Streamlit
- Exposer les donnÃ©es via une API REST documentÃ©e avec FastAPI
- IntÃ©grer avec AWS (S3, Glue, Athena) pour l'analyse Ã  grande Ã©chelle

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset    â”‚  Stock Market Historical Data (CSV)
â”‚     CSV      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Producerâ”‚  â€¢ Technical Indicators Calculation
â”‚    + Analytics   â”‚  â€¢ Alert Detection (Price/Volume)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ Structured JSON Logging
         â”‚
         â”‚ JSON Messages
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka    â”‚  â€¢ Distributed Message Queue
â”‚    + Zookeeper   â”‚  â€¢ Topic: stock_market_data
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ High Throughput & Reliability
         â”‚
         â”‚ Real-time Streaming
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced Consumerâ”‚  â€¢ Batch Processing (100 msg/batch)
â”‚   + Parquet      â”‚  â€¢ Parquet Format (90% compression)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â€¢ S3 Partitioning (date/symbol)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Storage Layer (S3 / Local)           â”‚
â”‚  output/stock_market_batch_*.parquet         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚           â”‚
    â–¼          â–¼          â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Streamlitâ”‚ â”‚FastAPIâ”‚ â”‚AWS Glue â”‚ â”‚ Athena  â”‚
â”‚Dashboardâ”‚ â”‚  API  â”‚ â”‚ Crawler â”‚ â”‚   SQL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Features

### ğŸš€ Pipeline de DonnÃ©es
- **Streaming Kafka** : Ingestion et traitement de donnÃ©es en temps rÃ©el
- **Analytics Automatiques** : Calcul d'indicateurs techniques (SMA, EMA, RSI, VolatilitÃ©)
- **Alertes Intelligentes** : DÃ©tection automatique de variations de prix et pics de volume
- **Batch Processing** : Traitement optimisÃ© par lots pour meilleures performances
- **Format Parquet** : Compression et stockage optimisÃ©s (90% d'Ã©conomie d'espace)

### ğŸ“Š Visualisation & API
- **Dashboard Interactif** : Interface Streamlit avec graphiques en temps rÃ©el
- **API REST** : FastAPI avec documentation Swagger automatique
- **Graphiques AvancÃ©s** : Chandeliers japonais, indicateurs techniques, volumes

### ğŸ—ï¸ Infrastructure
- **Docker Compose** : DÃ©ploiement Kafka en une commande
- **Configuration CentralisÃ©e** : Fichier YAML et variables d'environnement
- **AWS Integration** : Support S3, Glue, et Athena
- **Production-Ready** : Gestion d'erreurs, retry logic, logging structurÃ©

### ğŸ“ˆ Indicateurs Techniques CalculÃ©s

| Indicateur | Description | PÃ©riode |
|-----------|-------------|---------|
| **SMA** | Simple Moving Average | 20 et 50 jours |
| **EMA** | Exponential Moving Average | 12 jours |
| **RSI** | Relative Strength Index | 14 jours |
| **VolatilitÃ©** | Ã‰cart-type des rendements | 20 jours |
| **Changement de Prix** | Variation en pourcentage | Jour Ã  jour |
| **Volume Moyen** | Moyenne mobile du volume | 20 jours |

### ğŸ”Œ API Endpoints

- `GET /` - Informations API et liste des endpoints
- `GET /health` - Health check et statut du systÃ¨me
- `GET /stats` - Statistiques globales (messages, symboles, prix moyens)
- `GET /data` - DonnÃ©es avec filtres (pagination, symbole, dates)
- `GET /symbols` - Liste de tous les symboles disponibles
- `GET /symbol/{symbol}` - DonnÃ©es pour un symbole spÃ©cifique
- `GET /indicators/{symbol}` - Indicateurs techniques d'un symbole

---

## Requirements

### PrÃ©requis SystÃ¨me
- **Python** 3.8 ou supÃ©rieur
- **Docker** et Docker Compose
- **8GB RAM** minimum recommandÃ©
- **AWS CLI** configurÃ© (optionnel, pour S3)

### DÃ©pendances Python

Les dÃ©pendances sont listÃ©es dans `requirements.txt` et incluent :
- `kafka-python` - Client Kafka
- `pandas` - Traitement de donnÃ©es
- `pyarrow` - Format Parquet
- `fastapi` - API REST
- `streamlit` - Dashboard interactif
- `structlog` - Logging structurÃ©
- `s3fs` - IntÃ©gration AWS S3 (optionnel)

---

## Getting Started

### 1. Cloner le repository

```bash
git clone https://github.com/moaddebian/Real-Time-Stock-Market-Data-Engineering-Pipeline.git
cd Real-Time-Stock-Market-Data-Engineering-Pipeline
```

### 2. Installer les dÃ©pendances

```bash
# CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les packages
pip install -r requirements.txt
```

### 3. DÃ©marrer Kafka avec Docker

```bash
docker-compose up -d
```

### 4. VÃ©rifier l'installation

```bash
# VÃ©rifier les containers
docker ps

# AccÃ©der Ã  Kafka UI
# Ouvrir http://localhost:8080 dans votre navigateur
```

### 5. DÃ©marrer le Pipeline

**Terminal 1 - Producer** :
```bash
python -m src.producer_enhanced
```


**Terminal 2 - Consumer** :
```bash
python -m src.consumer_enhanced
```


**Terminal 3 - Dashboard** :
```bash
streamlit run dashboard.py
```

**Terminal 4 - API REST** (optionnel) :
```bash
uvicorn api.main:app --host 127.0.0.1 --port 8000 --reload
```


### Configuration

Tous les paramÃ¨tres sont configurables via `config/config.yaml` :

```yaml
kafka:
  bootstrap_servers: "localhost:9092"
  topic_name: "stock_market_data"

producer:
  send_interval: 1  # secondes entre messages
  max_messages: null  # null = infini

consumer:
  output_format: "parquet"  # json ou parquet
  batch_size: 100
  use_s3: false  # true pour AWS S3
  local_output_dir: "output"

analytics:
  enabled: true
  calculate_indicators: true
  alert_thresholds:
    price_change_percent: 5.0
    volume_spike_percent: 200.0
```

---

## Contact Me

<div align="center">

**MOAD DABYANE**

Data Engineer & Software Developer

[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/moaddebian)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/dabyane-moad/)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:mouaddebien@gmail.com)

Made with â¤ï¸ and â˜• by MOAD DABYANE

</div>

---

## License

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
